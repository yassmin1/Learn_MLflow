# 🧪 MLflow Course: From Tracking to Deployment

Welcome to the **MLflow Mastery Course**, your step-by-step guide to mastering end-to-end Machine Learning lifecycle management using the powerful **MLflow** Python library.

Whether you're a beginner experimenting with ML models or a professional deploying models at scale, this course will teach you how to track, manage, package, and serve your models—all using MLflow.

---

## 🔍 What is MLflow?

MLflow is an **open-source platform** designed to **manage the complete machine learning lifecycle**, including:

- 📊 Experiment tracking  
- 📦 Project packaging  
- 🧠 Model versioning and registry  
- 🚀 Deployment and serving  

This course uses real-world examples, hands-on code, and clear explanations to help you master every key feature of MLflow.

---

## 📚 Course Structure

The course is divided into **three main modules**, each building on the last:

---

## ✅ Module 1: MLflow Tracking

**Goal:** Learn how to track experiments, log models, and compare results.

### You will learn how to:
- Install MLflow and run your first experiment
- Manually log parameters, metrics, and models
- Use `mlflow.autolog()` to capture logs automatically
- Organize experiments using names and tags
- Visualize and compare runs using the MLflow UI and `search_runs()`

📘 **Key Notebooks:**
- 1.1: Introduction & Setup  
- 1.2: Manual Logging  
- 1.3: Autologging  
- 1.4: Exploring the MLflow UI  
- 1.5: Experiment Organization  

---

## 🚀 Module 2: MLflow Projects and Custom Models

**Goal:** Build reusable ML projects and custom deployable Python models.

### You will learn how to:
- Structure MLflow Projects using `MLproject`, `train.py`, and `conda.yaml`
- Use parameterized project runs with the CLI
- Automate multiple runs (e.g., hyperparameter search)
- Log models with different **flavors** (e.g., `sklearn`, `pyfunc`)
- Build and log custom Python models using `mlflow.pyfunc.PythonModel`

📘 **Key Notebooks:**
- 2.1: MLflow Projects Basics  
- 2.2: Parameterization in Projects  
- 2.3: Grid Search & Multiple Runs  
- 2.4: Logging with Model Flavors  
- 2.5: Custom Python Models  

---

## 🛠️ Module 3: Deployment & MLOps

**Goal:** Learn how to deploy, serve, and automate retraining with MLflow.

### You will learn how to:
- Bundle preprocessing/postprocessing logic into deployable models
- Serve models via REST API using `mlflow models serve`
- Build and serve Docker containers from MLflow models
- Automate retraining pipelines with parameter monitoring (CI/CD)
- Use MLflow in production-like workflows

📘 **Key Notebooks:**
- 3.1: Intro to Model Serving  
- 3.2: Packaging Pre/Postprocessing  
- 3.3: Serving with REST API  
- 3.4: Docker & Cloud Deployment  
- 3.5: CI/CD Automation with MLflow  

---

## 🧠 What You'll Build

By the end of this course, you’ll be able to:
- Track all your ML experiments with ease
- Package your ML code into reproducible projects
- Build flexible, real-world model pipelines
- Serve and monitor your models in production

---

## 🚧 Prerequisites

- Python 3.7+
- Basic knowledge of scikit-learn or similar ML libraries
- Familiarity with the command line

---

## 📎 How to Use

1. Open each module notebook in **Google Colab** or your local IDE.  
2. Follow the instructions, run the code, and explore the MLflow UI.  
3. Use the **assessment questions** to reinforce learning.  
4. Apply what you learn to your own projects!




