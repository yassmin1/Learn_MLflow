{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "48M-ikC7q7bY"
   },
   "source": [
    "### **Module 1.2: Manual Logging with MLflow** \n",
    "\n",
    "\n",
    "## üéØ **Learning Objectives Expanded**\n",
    "\n",
    "### 1Ô∏è‚É£ **Manually Log Hyperparameters (`alpha`)**\n",
    "\n",
    "* **What it means:**\n",
    "  Explicitly tracking the values of hyperparameters you use when training models, such as the regularization strength (`alpha`), directly within your code.\n",
    "\n",
    "* **Detailed Steps:**\n",
    "\n",
    "  * Specify hyperparameter explicitly:\n",
    "\n",
    "    ```python\n",
    "    alpha = 0.1\n",
    "    ```\n",
    "  * Log the hyperparameter in MLflow:\n",
    "\n",
    "    ```python\n",
    "    import mlflow\n",
    "    mlflow.log_param(\"alpha\", alpha)\n",
    "    ```\n",
    "\n",
    "* **Why it matters:**\n",
    "  Tracking hyperparameters makes it easy to understand which settings lead to the best performance, improving reproducibility and experiment tracking.\n",
    "\n",
    "---\n",
    "\n",
    "### 2Ô∏è‚É£ **Log Multiple Metrics (`mse`, `rmse`)**\n",
    "\n",
    "* **What it means:**\n",
    "  Recording different evaluation metrics to assess model performance, such as Mean Squared Error (MSE) and Root Mean Squared Error (RMSE).\n",
    "\n",
    "* **Detailed Steps:**\n",
    "\n",
    "  * Calculate your metrics after prediction:\n",
    "\n",
    "    ```python\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = mse ** 0.5\n",
    "    ```\n",
    "  * Log metrics explicitly:\n",
    "\n",
    "    ```python\n",
    "    mlflow.log_metric(\"mse\", mse)\n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "    ```\n",
    "\n",
    "* **Why it matters:**\n",
    "  Logging multiple metrics provides a comprehensive view of model quality, allowing for more informed decisions when comparing models.\n",
    "\n",
    "---\n",
    "\n",
    "### 3Ô∏è‚É£ **Iterate Over Multiple Model Configurations**\n",
    "\n",
    "* **What it means:**\n",
    "  Automatically training and logging multiple models with different configurations (hyperparameters) using loops.\n",
    "\n",
    "* **Detailed Steps:**\n",
    "\n",
    "  ```python\n",
    "  alphas = [0.01, 0.1, 1.0, 10.0]\n",
    "  for alpha in alphas:\n",
    "      with mlflow.start_run():\n",
    "          mlflow.log_param(\"alpha\", alpha)\n",
    "          \n",
    "          model = Ridge(alpha=alpha)\n",
    "          model.fit(X_train, y_train)\n",
    "          \n",
    "          y_pred = model.predict(X_test)\n",
    "          mse = mean_squared_error(y_test, y_pred)\n",
    "          rmse = mse ** 0.5\n",
    "          \n",
    "          mlflow.log_metric(\"mse\", mse)\n",
    "          mlflow.log_metric(\"rmse\", rmse)\n",
    "  ```\n",
    "\n",
    "* **Why it matters:**\n",
    "  Automating multiple runs efficiently helps identify optimal configurations, saving time and effort during model tuning.\n",
    "\n",
    "---\n",
    "\n",
    "### 4Ô∏è‚É£ **Compare and Sort Runs Using `mlflow.search_runs()`**\n",
    "\n",
    "* **What it means:**\n",
    "  Programmatically retrieving and analyzing logged model runs to identify top-performing models based on metrics.\n",
    "\n",
    "* **Detailed Steps:**\n",
    "\n",
    "  ```python\n",
    "  runs_df = mlflow.search_runs(experiment_names=[\"manual-logging-ridge\"])\n",
    "  runs_df_sorted = runs_df.sort_values(by=\"metrics.rmse\")\n",
    "  print(runs_df_sorted[[\"run_id\", \"params.alpha\", \"metrics.mse\", \"metrics.rmse\"]])\n",
    "  ```\n",
    "\n",
    "* **Why it matters:**\n",
    "  Quickly sorting and analyzing experiments allows you to identify which model configurations yield the best performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 611
    },
    "executionInfo": {
     "elapsed": 42020,
     "status": "ok",
     "timestamp": 1753616327368,
     "user": {
      "displayName": "Rayan Yassminh",
      "userId": "13160170557035890181"
     },
     "user_tz": -60
    },
    "id": "lrx0QlsQrOkg",
    "outputId": "f1f0b8ac-44f5-4d30-8e6e-29bea58960d7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/02 21:39:40 INFO mlflow.tracking.fluent: Experiment with name 'manual-logging-ridge' does not exist. Creating a new experiment.\n",
      "2025/08/02 21:39:40 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/08/02 21:39:44 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/08/02 21:39:45 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged run with alpha=0.01, Run ID=3b9ab8905ae044dda149d262150627cd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/02 21:39:48 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/08/02 21:39:48 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged run with alpha=0.1, Run ID=268c7a65e7564d179eefa431a52f2fe1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/02 21:39:52 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/08/02 21:39:52 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged run with alpha=1.0, Run ID=76a08172a4d8470bb22437c7ba10bac3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/02 21:39:55 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged run with alpha=10.0, Run ID=aa1b45c42c364478a8841d6f750802bb\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "run_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "params.alpha",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "metrics.mse",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "metrics.rmse",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "1756c6e9-01b3-4cfe-b223-5f66fc3952d2",
       "rows": [
        [
         "2",
         "268c7a65e7564d179eefa431a52f2fe1",
         "0.1",
         "2856.486887670654",
         "53.446111997699646"
        ],
        [
         "3",
         "3b9ab8905ae044dda149d262150627cd",
         "0.01",
         "2882.29018040601",
         "53.68696471589738"
        ],
        [
         "1",
         "76a08172a4d8470bb22437c7ba10bac3",
         "1.0",
         "3077.41593882723",
         "55.47446204180109"
        ],
        [
         "0",
         "aa1b45c42c364478a8841d6f750802bb",
         "10.0",
         "4443.95263666302",
         "66.66297800625937"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 4
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>params.alpha</th>\n",
       "      <th>metrics.mse</th>\n",
       "      <th>metrics.rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>268c7a65e7564d179eefa431a52f2fe1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2856.486888</td>\n",
       "      <td>53.446112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3b9ab8905ae044dda149d262150627cd</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2882.290180</td>\n",
       "      <td>53.686965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>76a08172a4d8470bb22437c7ba10bac3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3077.415939</td>\n",
       "      <td>55.474462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aa1b45c42c364478a8841d6f750802bb</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4443.952637</td>\n",
       "      <td>66.662978</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             run_id params.alpha  metrics.mse  metrics.rmse\n",
       "2  268c7a65e7564d179eefa431a52f2fe1          0.1  2856.486888     53.446112\n",
       "3  3b9ab8905ae044dda149d262150627cd         0.01  2882.290180     53.686965\n",
       "1  76a08172a4d8470bb22437c7ba10bac3          1.0  3077.415939     55.474462\n",
       "0  aa1b45c42c364478a8841d6f750802bb         10.0  4443.952637     66.662978"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# üìì Module 1.2: Manual Logging with MLflow\n",
    "# Goal: Learn how to log multiple runs with varying parameters manually and compare results in the MLflow UI or programmatically.\n",
    "\n",
    "# ‚úÖ Step 1: Install necessary packages\n",
    "!pip install -q mlflow scikit-learn\n",
    "\n",
    "# ‚úÖ Step 2: Import libraries\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# ‚úÖ Step 3: Load dataset and prepare train/test split\n",
    "# The diabetes dataset is a standard regression dataset available in sklearn\n",
    "# We will use it to predict disease progression using patient features\n",
    "diabetes = load_diabetes()\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    diabetes.data, diabetes.target, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# ‚úÖ Step 4: Set up experiment\n",
    "# All runs will be grouped under this named experiment for easy comparison\n",
    "mlflow.set_experiment(\"manual-logging-ridge\")\n",
    "\n",
    "# ‚úÖ Step 5: Run experiments manually with different alpha values\n",
    "# We will train a Ridge regression model using various values of alpha (regularization strength)\n",
    "alphas = [0.01, 0.1, 1.0, 10.0]\n",
    "\n",
    "for alpha in alphas:\n",
    "    # Start a new MLflow run\n",
    "    with mlflow.start_run():\n",
    "        # Log the hyperparameter 'alpha'\n",
    "        mlflow.log_param(\"alpha\", alpha)\n",
    "\n",
    "        # Train Ridge regression model\n",
    "        model = Ridge(alpha=alpha)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Predict on the test set and evaluate performance\n",
    "        y_pred = model.predict(X_test)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "\n",
    "        # Log evaluation metrics\n",
    "        mlflow.log_metric(\"mse\", mse)     # Mean Squared Error\n",
    "        mlflow.log_metric(\"rmse\", rmse)   # Root Mean Squared Error\n",
    "\n",
    "        # Log the trained model as an artifact\n",
    "        mlflow.sklearn.log_model(model, \"ridge_model\")\n",
    "\n",
    "        # Print run info to confirm logging\n",
    "        run_id = mlflow.active_run().info.run_id\n",
    "        print(f\"Logged run with alpha={alpha}, Run ID={run_id}\")\n",
    "\n",
    "# ‚úÖ Step 6: Compare runs\n",
    "# Fetch all completed runs in the experiment and sort by RMSE to find best performing configuration\n",
    "runs_df = mlflow.search_runs(experiment_names=[\"manual-logging-ridge\"])\n",
    "display_cols = [\"run_id\", \"params.alpha\", \"metrics.mse\", \"metrics.rmse\"]\n",
    "runs_df[display_cols].sort_values(\"metrics.rmse\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pm-pQD4SsF-t"
   },
   "source": [
    "## üìù Assessment: Manual Logging with MLflow\n",
    "\n",
    "### üìò Multiple Choice (Choose the best answer)\n",
    "\n",
    "**1. What is the purpose of `mlflow.log_param()` in MLflow?**    \n",
    "A. To train a model with logged parameters    \n",
    "B. To log runtime metrics during training    \n",
    "C. To save the trained model to disk    \n",
    "**D. To record a hyperparameter value used in an experiment** ‚úÖ    \n",
    "\n",
    "---\n",
    "\n",
    "**2. What does `mlflow.start_run()` do?**    \n",
    "A. Runs the model in a separate thread    \n",
    "B. Initializes the MLflow tracking server    \n",
    "**C. Starts a new context to log experiment data** ‚úÖ    \n",
    "D. Automatically saves the model to the registry    \n",
    "\n",
    "---\n",
    "\n",
    "**3. Which metric indicates how much the model's prediction error is, on average, in the same unit as the target?**    \n",
    "A. MSE    \n",
    "**B. RMSE** ‚úÖ    \n",
    "C. R¬≤    \n",
    "D. Accuracy    \n",
    "\n",
    "---\n",
    "\n",
    "**4. Which MLflow method is used to store the model artifact after training?**    \n",
    "A. `mlflow.save_model()`    \n",
    "**B. `mlflow.sklearn.log_model()`** ‚úÖ    \n",
    "C. `mlflow.track_model()`        \n",
    "D. `mlflow.write_model()`    \n",
    "\n",
    "---\n",
    "\n",
    "### ‚úèÔ∏è Short Answer\n",
    "\n",
    "**5. Explain the difference between MSE and RMSE. When might RMSE be preferred for interpretation?**    \n",
    "*Your answer should mention that MSE is the average squared error, while RMSE is its square root, offering a more interpretable value in the target‚Äôs original units.*\n",
    "\n",
    "---\n",
    "\n",
    "**6. What happens if you don‚Äôt use `mlflow.start_run()` before logging parameters or metrics?**    \n",
    "*Answer: MLflow will not track anything unless it's within a `start_run()` context. You might get an error or silent failure to log.*\n",
    "\n",
    "---\n",
    "\n",
    "### üß™ Mini Project\n",
    "\n",
    "**7. Task: Change the Ridge regression model to use `Lasso` instead.**    \n",
    "\n",
    "* Log the same `alpha` values    \n",
    "* Log `mse` and `rmse`    \n",
    "* Log the model using `mlflow.sklearn.log_model()`v\n",
    "* Compare and sort runs to find the best-performing one    \n",
    "\n",
    "‚úÖ *Bonus*: Can you add R¬≤ score (`r2_score`) as a new metric?    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyM+PdE6Z6ZtY6Y3g9JdbQL9",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
